{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvD8N9XMI/ejO3i4bL78Vd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leman-cap13/Machine_Learning/blob/main/user_wallet_transactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data downloading and preprocessing"
      ],
      "metadata": {
        "id": "w1ShNMpAIob_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WsjBxYl-Gai"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_path=\"/content/user-wallet-transactions.json\""
      ],
      "metadata": {
        "id": "wuuXlTsd_DHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "with open(json_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "eB8uoeU8-Mb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "56M71jNz_75n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "h35hO35w_2AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "nSem1IWAAJl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "araXbTFlALQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['_id'][0]"
      ],
      "metadata": {
        "id": "Wo0KSYolAMwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['actionData'][0]"
      ],
      "metadata": {
        "id": "ztn-Z5pVAQho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_actionData(row):\n",
        "    try:\n",
        "        amount = int(row.get('amount', 0)) / 1e6  # əgər USDC 6 desimallıdırsa\n",
        "    except:\n",
        "        amount = 0\n",
        "\n",
        "    asset = row.get('assetSymbol', 'UNKNOWN')\n",
        "    price = float(row.get('assetPriceUSD', 0))\n",
        "    type_ = row.get('type', 'UNKNOWN')\n",
        "    return pd.Series([amount, asset, price, type_])\n",
        "\n",
        "df[['amount', 'asset', 'price_usd', 'action_type']] = df['actionData'].apply(extract_from_actionData)\n"
      ],
      "metadata": {
        "id": "gS1DuRBgCaeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['amount_usd'] = df['amount'] * df['price_usd']\n"
      ],
      "metadata": {
        "id": "gpvRo_7eCcIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "g1PS6FztDBUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['updatedAt'][33]"
      ],
      "metadata": {
        "id": "-tXaLxHLDSvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['createdAt'][33]"
      ],
      "metadata": {
        "id": "KEUK12BTDSsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['_id'] = df['_id'].apply(lambda x: x['$oid'])"
      ],
      "metadata": {
        "id": "6iQHK8dIDSqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['userWallet'][0]"
      ],
      "metadata": {
        "id": "yrDVIffqDtxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def parse_mongo_date(d):\n",
        "    try:\n",
        "        return pd.to_datetime(d['$date'])\n",
        "    except:\n",
        "        return pd.NaT\n",
        "\n",
        "df['createdAt'] = df['createdAt'].apply(parse_mongo_date)\n"
      ],
      "metadata": {
        "id": "wMZNrCmtD_2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['createdAt']"
      ],
      "metadata": {
        "id": "XhJqfaRjECDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "xNJknq73E0KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['action'].unique())\n"
      ],
      "metadata": {
        "id": "aJGlD0UWE8ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_deposit'] = (df['action'].str.lower() == 'deposit').astype(int)\n",
        "df['is_deposit']"
      ],
      "metadata": {
        "id": "1rIC4cmjFAhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_borrow'] = (df['action'].str.lower() == 'borrow').astype(int)\n",
        "df['is_borrow']"
      ],
      "metadata": {
        "id": "Cen78UQHFDjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_repay'] = (df['action'].str.lower() == 'repay').astype(int)\n",
        "df['is_repay']"
      ],
      "metadata": {
        "id": "vRBdnEAgFFQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_redeem'] = (df['action'].str.lower() == 'redeemunderlying').astype(int)\n",
        "df['is_redeem']"
      ],
      "metadata": {
        "id": "6hKw2h7YFIBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_liquidation'] = (df['action'].str.lower() == 'liquidationcall').astype(int)\n",
        "df['is_liquidation']"
      ],
      "metadata": {
        "id": "EeddS8lNFJsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')"
      ],
      "metadata": {
        "id": "O5C9x0JfGK6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['timestamp'][0]"
      ],
      "metadata": {
        "id": "wifYcltxHC2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['timestamp'].dtype)"
      ],
      "metadata": {
        "id": "hESvAoAEHRc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = df['timestamp'].dt.date"
      ],
      "metadata": {
        "id": "xUVpIQNqG_wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'].dtype"
      ],
      "metadata": {
        "id": "C01EFuviHY_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "C9iAsin0P8QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.groupby('userWallet').agg(\n",
        "    total_txn_count = ('action', 'count'),\n",
        "    active_days = ('date', 'nunique'),\n",
        "    first_txn_date = ('timestamp', 'min'),\n",
        "    last_txn_date = ('timestamp', 'max'),\n",
        "    total_deposit_count = ('is_deposit', 'sum'),\n",
        "    total_borrow_count = ('is_borrow', 'sum'),\n",
        "    total_repay_count = ('is_repay', 'sum'),\n",
        "    total_liquidation_count = ('is_liquidation', 'sum'),\n",
        "    total_redeem_count = ('is_redeem', 'sum'),\n",
        "    total_amount_usd = ('amount_usd', 'sum'),\n",
        "    avg_amount_usd = ('amount_usd', 'mean'),\n",
        ")\n",
        "\n",
        "\n",
        "features['days_between_first_last'] = (features['last_txn_date'] - features['first_txn_date']).dt.days\n"
      ],
      "metadata": {
        "id": "IWgpeE5bFZz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['days_between_first_last'].unique()"
      ],
      "metadata": {
        "id": "YxNBnguSFZx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features['days_between_first_last'].value_counts().sort_index())\n",
        "\n",
        "print(features[['first_txn_date', 'last_txn_date']].head(10))\n"
      ],
      "metadata": {
        "id": "LAqMDpuBFZvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "active_days = df.groupby('userWallet')['date'].nunique()\n",
        "print(active_days.head())\n"
      ],
      "metadata": {
        "id": "Hl39CEf7Hk4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deposit_usd = df[df['is_deposit'] == 1].groupby('userWallet')['amount_usd'].sum().rename('total_deposit_usd')\n",
        "borrow_usd = df[df['is_borrow'] == 1].groupby('userWallet')['amount_usd'].sum().rename('total_borrow_usd')\n",
        "repay_usd = df[df['is_repay'] == 1].groupby('userWallet')['amount_usd'].sum().rename('total_repay_usd')\n",
        "\n",
        "features = features.join([deposit_usd, borrow_usd, repay_usd])\n"
      ],
      "metadata": {
        "id": "hUyVQzrVHzos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "Yb-R54rRHzmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "-KRQJr1RHzj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['borrow_deposit_ratio'] = features['total_borrow_usd'] / (features['total_deposit_usd'] + 1e-6)\n"
      ],
      "metadata": {
        "id": "r2QLVkmbIFw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['borrow_deposit_ratio']"
      ],
      "metadata": {
        "id": "7gbuFE4AIFq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['repay_borrow_ratio'] = features['total_repay_usd'] / (features['total_borrow_usd'] + 1e-6)\n",
        "features['repay_borrow_ratio']"
      ],
      "metadata": {
        "id": "EsWTHIb7IFo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['has_liquidation'] = (features['total_liquidation_count'] > 0).astype(int)\n",
        "features['has_liquidation']"
      ],
      "metadata": {
        "id": "jUQkFz1zIMNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['txns_per_active_day'] = features['total_txn_count'] / (features['active_days'] + 1e-9)\n",
        "features['liquidation_ratio'] = features['total_liquidation_count'] / (features['total_txn_count'] + 1e-9)\n",
        "features['borrow_repay_diff'] = features['total_borrow_count'] - features['total_repay_count']\n",
        "features['net_usd_flow'] = features['total_deposit_usd'] - features['total_borrow_usd']\n"
      ],
      "metadata": {
        "id": "vGsffyo8IdPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scoring function"
      ],
      "metadata": {
        "id": "ui51wsevcYAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_norm(x):\n",
        "    return (x - x.min()) / (x.max() - x.min() + 1e-9)"
      ],
      "metadata": {
        "id": "yjtavEd2JWsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_wallets(features_df):\n",
        "    txn_score = min_max_norm(features_df['total_txn_count'])\n",
        "    deposit_score = min_max_norm(features_df['total_deposit_count'])\n",
        "    borrow_score = min_max_norm(features_df['total_borrow_count'])\n",
        "    repay_score = min_max_norm(features_df['total_repay_count'])\n",
        "    liquidation_score = 1 - min_max_norm(features_df['total_liquidation_count'])\n",
        "    amount_score = min_max_norm(features_df['total_amount_usd'])\n",
        "\n",
        "    # Yeni feature-lər:\n",
        "    txns_per_day_score = min_max_norm(features_df['txns_per_active_day'])\n",
        "    liquidation_ratio_score = 1 - min_max_norm(features_df['liquidation_ratio'])\n",
        "    borrow_repay_diff_score = 1 - min_max_norm(features_df['borrow_repay_diff'].clip(lower=0))\n",
        "    net_usd_flow_score = min_max_norm(features_df['net_usd_flow'].clip(lower=0))\n",
        "\n",
        "    # weights ilə birlikdə\n",
        "    weights = {\n",
        "        'txn': 0.15,\n",
        "        'deposit': 0.1,\n",
        "        'borrow': 0.1,\n",
        "        'repay': 0.1,\n",
        "        'liquidation': 0.15,\n",
        "        'amount': 0.1,\n",
        "        'txns_per_day': 0.1,\n",
        "        'liquidation_ratio': 0.1,\n",
        "        'borrow_repay_diff': 0.05,\n",
        "        'net_usd_flow': 0.05,\n",
        "    }\n",
        "\n",
        "    score = (\n",
        "        txn_score * weights['txn'] +\n",
        "        deposit_score * weights['deposit'] +\n",
        "        borrow_score * weights['borrow'] +\n",
        "        repay_score * weights['repay'] +\n",
        "        liquidation_score * weights['liquidation'] +\n",
        "        amount_score * weights['amount'] +\n",
        "        txns_per_day_score * weights['txns_per_day'] +\n",
        "        liquidation_ratio_score * weights['liquidation_ratio'] +\n",
        "        borrow_repay_diff_score * weights['borrow_repay_diff'] +\n",
        "        net_usd_flow_score * weights['net_usd_flow']\n",
        "    )\n",
        "\n",
        "    score = score * 1000\n",
        "    return score.round().astype(int)\n"
      ],
      "metadata": {
        "id": "qD5CCuvbJA_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['credit_score'] = score_wallets(features)\n",
        "print(features[['credit_score']].head())\n"
      ],
      "metadata": {
        "id": "mHFeF1oUJIe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['credit_score'] = score_wallets(features)\n",
        "print(features[['credit_score']].describe())\n"
      ],
      "metadata": {
        "id": "N_qmLy4cJdVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization"
      ],
      "metadata": {
        "id": "-K-bbvDjQOWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.histplot(features['credit_score'], bins=50, kde=True)\n",
        "plt.title('Credit Score Paylanması (Histogram)')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(x=features['credit_score'])\n",
        "plt.title('Credit Score Paylanması (Boxplot)')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rYDpiy3UJdSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Left plot (Histogram):\n",
        "This shows how credit scores are spread across all wallets. The bars represent how many wallets fall into each score range, and the smooth line (KDE) estimates the overall shape of the distribution. It helps us see where most scores concentrate and if there are any unusual peaks or gaps.\n",
        "\n",
        "Right plot (Boxplot):\n",
        "This summarizes the credit score distribution using five key statistics: minimum, first quartile (25%), median (50%), third quartile (75%), and maximum. It also helps identify any outliers. The boxplot gives a quick overview of the central tendency and variability of the scores."
      ],
      "metadata": {
        "id": "9P9S_QCzKcNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_score = features[features['credit_score'] <= 200]\n",
        "high_score = features[features['credit_score'] >= 500]\n",
        "\n",
        "print(\"Number of wallets with low score:\", len(low_score))\n",
        "print(\"Number of wallets with high score:\", len(high_score))\n",
        "\n",
        "print(\"Average transaction count for low score wallets:\", low_score['total_txn_count'].mean())\n",
        "print(\"Average transaction count for high score wallets:\", high_score['total_txn_count'].mean())\n",
        "\n",
        "print(\"Average liquidation count for low score wallets:\", low_score['total_liquidation_count'].mean())\n",
        "print(\"Average liquidation count for high score wallets:\", high_score['total_liquidation_count'].mean())\n"
      ],
      "metadata": {
        "id": "6g4XJTsYJdQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "corr = features[['credit_score', 'total_txn_count', 'total_liquidation_count']].corr()\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JCEye_oFJ4H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap shows how strongly these variables relate to each other. The colors indicate the direction and strength of the relationship — blue means a strong positive correlation, red means a strong negative correlation, and colors near white mean little or no correlation.\n",
        "\n",
        "For example, we see a strong positive correlation between total transaction count and credit score, meaning as transactions increase, the score tends to increase too. On the other hand, total liquidation count has a negative correlation with credit score, showing that more liquidations usually lead to a lower score."
      ],
      "metadata": {
        "id": "pcfGJrrfKSh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.scatterplot(data=features, x='total_txn_count', y='credit_score')\n",
        "plt.title('Credit Score vs Total Transaction Count')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.scatterplot(data=features, x='total_liquidation_count', y='credit_score')\n",
        "plt.title('Credit Score vs Total Liquidation Count')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LONqg_0xJ4FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the left graph, you can see that wallets with more transactions usually have higher credit scores. This makes sense because wallets that interact more often with the protocol tend to be more reliable or valuable.\n",
        "\n",
        "On the right graph, the opposite happens. Wallets with more liquidations tend to have lower credit scores. That’s expected since liquidations show risky or problematic behavior, so those wallets get penalized in their score.\n",
        "\n",
        "So basically, more activity usually means better trustworthiness, while more liquidations mean higher risk and a lower score."
      ],
      "metadata": {
        "id": "c1CG4jM4KKvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model preparation"
      ],
      "metadata": {
        "id": "kM4m9VFsQSuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "vqkjpfBpLEl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.columns.tolist())\n"
      ],
      "metadata": {
        "id": "NWvRo7oXMP00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = [\n",
        "    'total_txn_count', 'active_days', 'total_deposit_count',\n",
        "    'total_borrow_count', 'total_repay_count', 'total_liquidation_count',\n",
        "    'total_redeem_count', 'total_amount_usd', 'avg_amount_usd',\n",
        "    'days_between_first_last', 'total_deposit_usd', 'total_borrow_usd',\n",
        "    'total_repay_usd', 'borrow_deposit_ratio', 'repay_borrow_ratio',\n",
        "    'has_liquidation', 'txns_per_active_day', 'liquidation_ratio',\n",
        "    'borrow_repay_diff', 'net_usd_flow'\n",
        "]\n",
        "\n",
        "\n",
        "categorical_features = []"
      ],
      "metadata": {
        "id": "vdls6e6_LnZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Data hazırlanması\n",
        "X = features[numeric_features]\n",
        "y = features['credit_score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Pipeline qurulması\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('xgb', XGBRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        verbosity=1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Modelin tren edilməsi\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "fgzv2reJMb0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R2:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "EZN3TDTkMsmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.named_steps['xgb']\n",
        "\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "feature_names = X.columns\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances (Gain)\")\n",
        "plt.bar(range(len(importances)), importances[indices])\n",
        "plt.xticks(range(len(importances)), feature_names[indices], rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pEQbA5cXM24a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_scores = pipeline.predict(X)\n",
        "\n",
        "\n",
        "scores_scaled = 1000 * (all_scores - np.min(all_scores)) / (np.max(all_scores) - np.min(all_scores))\n",
        "\n",
        "features['credit_score_pred'] = scores_scaled\n"
      ],
      "metadata": {
        "id": "eJiALEF4uen8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_scores"
      ],
      "metadata": {
        "id": "ZmU_q7fnutOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_scaled"
      ],
      "metadata": {
        "id": "s99aXJ0-utMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features['credit_score_pred']"
      ],
      "metadata": {
        "id": "dlyXK480ux4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bins = list(range(0, 1100, 100))\n",
        "labels = [f\"{i}-{i+99}\" for i in bins[:-1]]\n",
        "\n",
        "features['score_group'] = pd.cut(features['credit_score_pred'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "score_distribution = features['score_group'].value_counts().sort_index()\n",
        "\n",
        "print(score_distribution)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "score_distribution.plot(kind='bar')\n",
        "plt.title(\"Credit Score Distribution (0-1000)\")\n",
        "plt.xlabel(\"Score Range\")\n",
        "plt.ylabel(\"Number of Wallets\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V5octptUu2zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bins = [0, 500, 750, 1000]\n",
        "labels = ['0-499', '500-749', '750-1000']\n",
        "features['score_group_broad'] = pd.cut(features['credit_score_pred'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "print(features['score_group_broad'].value_counts())\n",
        "\n",
        "\n",
        "low_score_wallets = features[features['score_group_broad'] == '0-499']\n",
        "print(low_score_wallets.describe())\n",
        "\n",
        "high_score_wallets = features[features['score_group_broad'] == '750-1000']\n",
        "print(high_score_wallets.describe())\n"
      ],
      "metadata": {
        "id": "XICSwfOmvD5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(features['credit_score'], bins=30, kde=True)\n",
        "plt.title(\"Credit Score Distribution\")\n",
        "plt.xlabel(\"Credit Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(x=features['total_txn_count'], y=features['credit_score'])\n",
        "plt.title(\"Total Transactions vs Credit Score\")\n",
        "plt.xlabel(\"Total Transaction Count\")\n",
        "plt.ylabel(\"Credit Score\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x=features['score_group_broad'], y=features['total_txn_count'])\n",
        "plt.title(\"Total Transactions by Credit Score Group\")\n",
        "plt.xlabel(\"Score Group\")\n",
        "plt.ylabel(\"Total Transactions\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A2h7XlpivZdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model interpration (SHAP)"
      ],
      "metadata": {
        "id": "t94icyMTQW9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "id": "-LQLdQUyM22A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "\n",
        "explainer = shap.Explainer(model)\n",
        "\n",
        "\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "\n",
        "shap.summary_plot(shap_values, X_test)\n"
      ],
      "metadata": {
        "id": "N3P5V8xXM2zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using SHAP (SHapley Additive exPlanations) to interpret our XGBoost credit scoring model. SHAP helps us understand how each feature impacts the model’s predictions for each wallet."
      ],
      "metadata": {
        "id": "FkDzLulgNfGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "First, we create a SHAP explainer by giving it our trained model. This explainer figures out how each feature affects the prediction for every wallet.\n",
        "\n",
        "Then, we run the explainer on our test data, and it calculates something called SHAP values for each feature. These values basically tell us: “How much did this feature push the score up or pull it down?”\n",
        "\n",
        "Finally, we visualize these SHAP values using a summary plot. On this plot, each feature is listed from most to least important. The points show the effect of that feature on the prediction for all wallets, and the color shows whether the feature value was high or low.\n",
        "\n",
        "For example, if a wallet has a lot of transactions (total_txn_count), SHAP will show that this feature usually increases the credit score. Conversely, if a wallet has many liquidations (total_liquidation_count), SHAP will reveal that this feature tends to decrease the score.\n",
        "\n",
        "In short, SHAP lets us see exactly why our model gave a certain score — which features were driving that decision — and helps us trust and explain the model better."
      ],
      "metadata": {
        "id": "PxXr3Q8wNgNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter tuning (Optuna)"
      ],
      "metadata": {
        "id": "u5Wj_LIaQgnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "id": "xMG79g92Ns5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "    }\n",
        "    model = XGBRegressor(**params, random_state=42)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='r2')\n",
        "    return scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best params:\", study.best_params)\n",
        "print(\"Best R2:\", study.best_value)\n"
      ],
      "metadata": {
        "id": "oWERgfaON596"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "so this code uses a tool called Optuna to help us find the best settings for our XGBoost model without us having to guess or try every possible combination ourselves.\n",
        "\n",
        "Basically, we write a little function — that’s the objective — which tells Optuna:\n",
        "“Here’s how you test one set of parameters. Train the model with these, check how well it does, and give me the score.”\n",
        "\n",
        "Inside that function, we say:\n",
        "\n",
        "Try tree depths between 3 and 10.\n",
        "\n",
        "Try learning rates somewhere between 0.01 and 0.3.\n",
        "\n",
        "Try different numbers of trees — from 100 to 1000.\n",
        "\n",
        "Also tweak what fraction of the data and features the model uses for each tree.\n",
        "\n",
        "For each set, the function builds a model and checks how well it predicts using cross-validation. Cross-validation just means we split the training data into parts to make sure the model really generalizes well, not just memorizes.\n",
        "\n",
        "Then Optuna runs this function 50 times — each time with different parameters — and keeps track of which combination gives the best R-squared score (basically how well the model fits the data).\n",
        "\n",
        "At the end, it tells us the best parameters it found and the best score.\n",
        "\n",
        "So instead of manually trying different values and hoping for the best, Optuna does the heavy lifting — smartly exploring the options and giving us the best model setup."
      ],
      "metadata": {
        "id": "HyBZQhfwOXl6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cA49jxnBOYph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}